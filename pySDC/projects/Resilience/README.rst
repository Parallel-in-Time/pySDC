Resilience in SDC
=================

In this project, we try a few methods for fixing bitflips in the solution caused by external factors such as radiation.
For convenience, we show here plots of tests which are generated by the continuous integration pipeline on GitHub, meaning they are always generated by the latest master branch, while showing explanations in jupyter notebooks, which show only a fixed commit.

The first strategy we try is `Adaptivity <https://github.com/Parallel-in-Time/pySDC/blob/master/pySDC/projects/Resilience/Adaptivity.ipynb>`_, which continually adjusts the step size during run-time and comes with resilience as a by product.

The second strategy is `Hot Rod <https://github.com/Parallel-in-Time/pySDC/blob/master/pySDC/projects/Resilience/HotRod.ipynb>`_, which is designed purely as a detector for soft faults.

We have also simulated faults in the van der Pol problem and tried recovering them with the strategies `here <https://github.com/Parallel-in-Time/pySDC/blob/master/pySDC/projects/Resilience/ResilienceStatistics.ipynb>`_.
We also experimented with faults in the Lorenz attractor problem `here <https://github.com/Parallel-in-Time/pySDC/blob/master/pySDC/projects/Resilience/notes/LorenzResilience.md>`_.

Tests
-----
Please refer to the above mentioned notebooks for thorough descriptions of what you are seeing here.
These plots are duplicates of what you can find there, but generated with the latest master branch.

The Piline equation models an electrical start-up process and is a system of ordinary differential equations, that shows some slowing down of the time scale and is hence a good test to check adaptivity with.
See below for, in the order of mention, plots of the solution, the error estimates with difference for Hot Rod and time step with adaptivity enabled and the same with fixed time step and the order of the error estimates with different numbers of sweeps.
The last plot was made without Hot Rod, meaning the last sweep is taken to be the solution of the time step, making it one order higher than the embedded estimate, and it can be seen that the extrapolation error estimate lies on top of the embedded error estimate with one fewer sweep.
These plots were generated with serial SDC.

.. image:: ../../../data/piline_solution_adaptive.png
    :width: 20%
.. image:: ../../../data/piline_hotrod_adaptive_1procs.png
    :width: 24%
.. image:: ../../../data/piline_hotrod_1procs.png
    :width: 24%
.. image:: ../../../data/error_estimate_order.png
    :width: 23%

We also have an implementation for Block Gauss-Seidel multi-step SDC in a simulated parallelism version without MPI.
You can see the results below, except for the solution, which looks the same as the serial solution to the naked eye.
 
.. image:: ../../../data/piline_hotrod_adaptive_4procs.png
    :width: 24%
.. image:: ../../../data/piline_hotrod_4procs.png
    :width: 24%
.. image:: ../../../data/error_estimate_order_parallel.png
    :width: 23%


Reproduction of the plots in the adaptive SDC paper
---------------------------------------------------
To reproduce the plots you need to install pySDC with all packages in the mpi4py environment.
Then, navigate to this directory, `pySDC/projects/Resilience/` and run the following commands:

 
.. code-block:: bash
 
    mpirun -np 4 python work_precision.py
    mpirun -np 4 python fault_stats.py prob run_vdp
    mpirun -np 4 python fault_stats.py prob run_quench
    mpirun -np 4 python fault_stats.py prob run_AC
    mpirun -np 4 python fault_stats.py prob run_Schroedinger
    python paper_plots.py

Possibly, you need to create some directories in this one to store and load things, if path errors occur.
